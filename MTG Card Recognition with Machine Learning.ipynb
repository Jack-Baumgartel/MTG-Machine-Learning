{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries & define our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFilter, ImageEnhance\n",
    "import imagehash\n",
    "from urllib.request import urlopen\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import shutil\n",
    "from time import localtime, strftime, time\n",
    "from natsort import natsorted\n",
    "from IPython.display import display\n",
    "\n",
    "def current_time():\n",
    "    '''Help: Returns the current time as a nice string.'''\n",
    "    return strftime(\"%B %d, %-I:%M%p\", localtime())\n",
    "\n",
    "def elapsed_time(start_time):\n",
    "    '''Using seconds since epoch, determine how much time has passed since the provided float. Returns string\n",
    "    with hours:minutes:seconds'''\n",
    "    elapsed_seconds = time()-start_time\n",
    "    h = int(elapsed_seconds/3600)\n",
    "    m = int((elapsed_seconds-h*3600)/60)\n",
    "    s = int((elapsed_seconds-m*60)-h*3600)\n",
    "    return f'{h}hr {m}m {s}s'\n",
    "\n",
    "#simple function to pickle variables for later use. save a local pickle\n",
    "def save_object(obj, filename, verbose=True):\n",
    "    '''Help: Given an object & filepath, store the object as a pickle for later use.'''\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    if verbose:\n",
    "        print(f\"File saved at {filename}\")\n",
    "    \n",
    "#and later load the file back into a variable\n",
    "def load_object(filename, verbose=True):\n",
    "    '''Help: Loads something previously pickled from the provided file path.'''\n",
    "    with open(filename, 'rb') as f:\n",
    "        load_test = pickle.load(f)\n",
    "    if verbose:\n",
    "        print(f\"File loaded from {filename}\")\n",
    "    return load_test\n",
    "\n",
    "def zoom_rotate_img(image):\n",
    "    '''Help: Randomly rotate and zoom the given PIL image degrees and return it'''\n",
    "    #store initial image size\n",
    "    initial_size = image.size\n",
    "    #determine at random how much or little we scale the image\n",
    "    scale = 0.95+random.random()*.1\n",
    "    scaled_img_size = tuple([int(i*scale) for i in initial_size])\n",
    "\n",
    "\n",
    "    #create a blank background with a random color and same size as intial image\n",
    "    bg_color = tuple(np.random.choice(range(256),size=3))\n",
    "    background = Image.new('RGB', initial_size, bg_color)\n",
    "\n",
    "    #determine the center location to place our rotated card\n",
    "    center_box = tuple((n-o)//2 for n,o in zip(initial_size, scaled_img_size))\n",
    "\n",
    "    #scale the image\n",
    "    scaled_img = image.resize(scaled_img_size)\n",
    "\n",
    "    #randomly select an angle to skew the image\n",
    "    max_angle = 5\n",
    "    skew_angle = random.randint(-max_angle, max_angle)\n",
    "    \n",
    "    #add the scaled image to our color background\n",
    "    background.paste(scaled_img.rotate(skew_angle, fillcolor=bg_color,expand=1).resize(scaled_img_size), \n",
    "                     center_box)\n",
    "\n",
    "    #potentially flip the image 180 degrees\n",
    "    if random.choice([True, False]):\n",
    "        background = background.rotate(180)\n",
    "    \n",
    "    return background\n",
    "\n",
    "def blur_img(image):\n",
    "    '''Help: Blur the given PIL image and return it'''\n",
    "    return image.filter(filter=ImageFilter.BLUR)\n",
    "\n",
    "def adjust_color(image):\n",
    "    '''Help: Randomly reduce or increase the saturation of the provided image and return it'''\n",
    "    converter = ImageEnhance.Color(image)\n",
    "    #randomly decide to half or double the image saturation\n",
    "    saturation = random.choice([.5, 1.5])\n",
    "    return converter.enhance(saturation)\n",
    "\n",
    "def adjust_contrast(image):\n",
    "    '''Help: Randomly decrease or increase the contrast of the provided image and return it'''\n",
    "    converter = ImageEnhance.Contrast(image)\n",
    "    #randomly decide to half or double the image saturation\n",
    "    contrast = random.choice([.5, 1.5])\n",
    "    return converter.enhance(contrast)\n",
    "\n",
    "def adjust_sharpness(image):\n",
    "    '''Help: Randomly decrease or increase the sharpness of the provided image and return it'''\n",
    "    converter = ImageEnhance.Sharpness(image)\n",
    "    #randomly decide to half or double the image saturation\n",
    "    sharpness = random.choice([.5, 1.5])\n",
    "    return converter.enhance(sharpness)\n",
    "\n",
    "def random_edit_img(image, distort=True, verbose=True):\n",
    "    '''Help: Make poor edits to the image at random and return the finished copy. Can optionally not distort\n",
    "    the image if need be.'''\n",
    "    \n",
    "    if distort:\n",
    "        #randomly choose which editing operations to perform\n",
    "        edit_permission = np.random.choice(a=[False, True], size=(4))\n",
    "\n",
    "        #always skew the image, randomly make the other edits\n",
    "        image = zoom_rotate_img(image)\n",
    "        if verbose:\n",
    "            print('Image skewed')\n",
    "        if edit_permission[0]:\n",
    "            image = blur_img(image)\n",
    "            if verbose:\n",
    "                print('Image blurred')    \n",
    "        if edit_permission[1]:\n",
    "            image = adjust_color(image)\n",
    "            if verbose:\n",
    "                print('Image color adjusted')\n",
    "        if edit_permission[2]:\n",
    "            image = adjust_contrast(image)\n",
    "            if verbose:\n",
    "                print('Image contrast adjusted')\n",
    "        if edit_permission[3]:\n",
    "            image = adjust_sharpness(image)\n",
    "            if verbose:\n",
    "                print('Image sharpness adjusted')\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def generate_distorted_imgs(multiverse_id_list, num_distortions, num_undistorted, storage_path, \\\n",
    "                            resize=False, img_size=(224,312)):\n",
    "    '''Help: High level function to reduce the testing & training image creation process down to a single step. \n",
    "    Provide a string list of multiverse_ids, the number of distortions desired for each printing, a general \n",
    "    storage location for the image files, and the final image size desired. Creates \"poorly photographed\" \n",
    "    versions of each multiverse_id printing provided. Results are named based on their index in the list.'''\n",
    "    \n",
    "    image_size = 'large'\n",
    "    \n",
    "    images_created = 0\n",
    "    printings_distorted = 0\n",
    "    #iterate through the provided list\n",
    "    for multiverse_id in multiverse_id_list:\n",
    "        printings_distorted += 1\n",
    "        #pull the image URL using the multiverse_id\n",
    "        image_url = modified_light_df_en[modified_light_df_en['multiverse_ids']\\\n",
    "                                         == int(multiverse_id)]['image_uris'].values[0][image_size]\n",
    "        #get the raw image file\n",
    "        clean_img = Image.open(urlopen(image_url))\n",
    "\n",
    "        #use the index instead of multiverse_id in filename\n",
    "        print_index = multiverse_id_list.index(multiverse_id)\n",
    "\n",
    "        #now produce poorly rendered versions of the printing\n",
    "        for i in range(num_distortions):\n",
    "            images_created += 1\n",
    "            if i < num_undistorted:\n",
    "                distorted_img = random_edit_img(clean_img, distort=False, verbose=False)\n",
    "            else:\n",
    "                distorted_img = random_edit_img(clean_img, verbose=False)\n",
    "\n",
    "            #potentially resize the image and save it locally #.resize((224,312))\n",
    "            if resize:\n",
    "                distorted_img = distorted_img.resize(img_size)\n",
    "                \n",
    "            distorted_img.save(f\"{storage_path}/{print_index}-{i}.jpg\")\n",
    "            \n",
    "    print(f\"\\n{images_created} total unique distortions saved from {printings_distorted} different printings.\")\n",
    "    print(f\"Images stored @ '{storage_path}'\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def prep_images_for_network(storage_path):\n",
    "    '''Help: Given a folder of distorted printings, compile all images and their labels into arrays for\n",
    "    neural network processing. Returns image_array, label_array'''\n",
    "    \n",
    "    #initialize the empty arrays\n",
    "    image_array = []\n",
    "    label_array = np.array([], dtype=int)\n",
    "\n",
    "    for subdir, dirs, files in os.walk(storage_path):\n",
    "        for file in np.sort(files):\n",
    "            if file.endswith('.jpg'):\n",
    "                #open the image, then convert it to an array and scale values from 0-1\n",
    "                image = Image.open(f\"{storage_path}/{file}\")\n",
    "                scaled_array = np.array(image)/255\n",
    "\n",
    "                #pull the multiverse_id from the filename\n",
    "                label = int(file.split('-')[0])\n",
    "\n",
    "                #add the data\n",
    "                image_array.append(scaled_array)\n",
    "                label_array = np.append(label_array, label)\n",
    "\n",
    "    #convert image list to numpy array\n",
    "    image_array = np.array(image_array)\n",
    "    \n",
    "    return image_array, label_array\n",
    "\n",
    "\n",
    "#single code block to generate distorted images, prep them for training, and save the arrays. all work is saved \n",
    "#in a new directory that is created for this run. also saves a description of the model\n",
    "\n",
    "def generate_img_set(image_set_name, multiverse_id_list, num_distortions, resize=True, verbose=True):\n",
    "    '''Help: Given appropriate parameters, generate num_distortions distorted image copies of each card in \n",
    "    multiverse_id_list. Then prep all the images for neural net training and save the resulting arrays.\n",
    "    Returns model_data: ((training_images, training_labels), (testing_images, testing_labels))\n",
    "    \n",
    "    image_set_name: str, desired folder name of current image set\n",
    "    multiverse_ids_list, list of ints, card printings to use\n",
    "    num_distortions, number of warped copies of each card to create\n",
    "    resize, boolean, if false, images keep 936,672 original resolution, otherwise resize to (224,312)\n",
    "    verbose, boolean, if true print statements show function progress\n",
    "    '''\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Process started for {image_set_name} on {current_time()} ...\")\n",
    "        start_time = time()\n",
    "\n",
    "    #if the folder already exists, delete it so we can start fresh\n",
    "    if os.path.exists(image_set_name):\n",
    "        shutil.rmtree(image_set_name)\n",
    "\n",
    "    #now create the directory, and sub folders for image storage\n",
    "    os.mkdir(image_set_name)\n",
    "    os.mkdir(f'{image_set_name}/Testing')\n",
    "    os.mkdir(f'{image_set_name}/Training')\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Folder structure created, generating {len(multiverse_id_list)*num_distortions} \\\n",
    "training images now ...')\n",
    "\n",
    "    #now create images for training and testing, testing will always have two images, change here if need be\n",
    "    #create the training images\n",
    "    training_storage_path = f\"{image_set_name}/Training\"\n",
    "    num_undistorted = 3\n",
    "    generate_distorted_imgs(multiverse_id_list, num_distortions, num_undistorted, training_storage_path, resize)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Training images finished on {current_time()}, now generating {len(multiverse_id_list)*2} \\\n",
    "testing images ...\")\n",
    "\n",
    "    #create the testing images\n",
    "    testing_storage_path = f\"{image_set_name}/Testing\"\n",
    "    num_undistorted = 1\n",
    "    generate_distorted_imgs(multiverse_id_list, 2, num_undistorted, testing_storage_path, resize)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"All images created and saved under {image_set_name} on {current_time()}. \\n\\\n",
    "Formatting images and labels for neural net processing now ...\")\n",
    "\n",
    "    #now open up all the image files and store contents as arrays for the neural net\n",
    "    training_images, training_labels = prep_images_for_network(training_storage_path)\n",
    "    testing_images, testing_labels = prep_images_for_network(testing_storage_path)\n",
    "\n",
    "    #save the input arrays locally for later use in case we want them\n",
    "    model_data = ((training_images, training_labels), (testing_images, testing_labels))\n",
    "    save_object(model_data, f'{image_set_name} Arrays.p', verbose=False)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Pre processing complete on {current_time()} after {elapsed_time(start_time)}. \\\n",
    "\\n\\nTraining & testing data saved locally ({image_set_name} Arrays.p) and ready for neural network!\\n\\n\")\n",
    "\n",
    "    return model_data\n",
    "\n",
    "\n",
    "def train_CNN_model(model_name, model_data, unique_printings, epochs=10, verbose=True):\n",
    "    '''Help: Create and train a CNN model for the provided model_data'''\n",
    "    \n",
    "    #unpack the model_data variable\n",
    "    ((training_images, training_labels), (testing_images, testing_labels)) = model_data\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Initializing {model_name} on {current_time()} ...')\n",
    "        model_start_time = time()\n",
    "\n",
    "    #if the folder already exists, delete it so we can start fresh\n",
    "    if os.path.exists(f'{model_name}.model'):\n",
    "        shutil.rmtree(f'{model_name}.model')\n",
    "\n",
    "    #initialize the neural network model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=training_images.shape[1:]))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(2,2))\n",
    "    model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(unique_printings, activation='softmax'))\n",
    "\n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    if verbose:\n",
    "        print('Network compiled, fitting data now ... \\n')\n",
    "    #fit the model to the provided data\n",
    "    model.fit(training_images, training_labels, epochs=epochs, validation_data=(testing_images, testing_labels))\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nModel fit, elvaluating accuracy and saving locally now ... \\n')\n",
    "    #evaluate the model\n",
    "\n",
    "    loss, accuracy = model.evaluate(testing_images, testing_labels)\n",
    "    print(f'Loss: {loss}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    #save it locally for future reuse\n",
    "    model.save(f'{model_name}.model')\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nModel evaluated & saved locally at '{model_name}.model' on {current_time()} \\\n",
    "after {elapsed_time(model_start_time)}!\\n\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model_via_index(image_set_name, card_index, model, sub_index = 0):\n",
    "    filepath = f'{image_set_name}/Testing/{card_index}-{sub_index}.jpg'\n",
    "    test_card = Image.open(filepath)\n",
    "\n",
    "    #provide the image to the model and see what comes back\n",
    "    img_as_array = np.array(np.array(test_card)/255)\n",
    "\n",
    "    eval_images = []\n",
    "    eval_images.append(img_as_array)\n",
    "    eval_images = np.array(eval_images)\n",
    "\n",
    "    result = model.predict(eval_images)\n",
    "    result_index, confidence = np.argmax(result), result[0,np.argmax(result)]\n",
    "\n",
    "    correct = False\n",
    "    #display the result!\n",
    "    if result_index == card_index:\n",
    "        #display(test_card)\n",
    "        correct = True\n",
    "        print(f'For card index {card_index}, model predicted index {result_index} \\\n",
    "with {np.round(confidence*100,4)}% confidence.')\n",
    "    \n",
    "    else:\n",
    "        print(f'For card index {card_index}, model predicted index {result_index} \\\n",
    "with {np.round(confidence*100,4)}% confidence. (INCORRECT)')\n",
    "        #display(test_card, Image.open(f'{image_set_name}/Testing/{result_index}-sub_index.jpg'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the modified scryfall database of cards, and the list subset of valid options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load english card database where multiverse_ids have been changed from lists to a single int value\n",
    "modified_light_df_en = load_object('modified_light_df_en.p')\n",
    "\n",
    "#and load the accompanying list of multiverse_ids suitable to use\n",
    "valid_multiverse_ids = load_object('Valid Multiverse IDs.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now select at random a few cards to use as a sample set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose at random 100 of those cards sorted numerically by multiverse_id\n",
    "num_unique_prints = 100\n",
    "chosen_multiverse_ids = natsorted(random.sample(valid_multiverse_ids, num_unique_prints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training & testing data from the chosen card set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define necessary variables and prepare all images for neural network training\n",
    "\n",
    "image_set_name = 'Demo Sample'\n",
    "multiverse_id_list = chosen_multiverse_ids\n",
    "num_distortions = 10\n",
    "resize = True\n",
    "verbose = True\n",
    "\n",
    "demo_model_data = generate_img_set(image_set_name, multiverse_id_list, num_distortions, resize, verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a neural network to recognize the cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide information about the model and train it!\n",
    "model_name = 'Demo Sample Model'\n",
    "epochs = 10\n",
    "verbose = True\n",
    "\n",
    "demo_model = train_CNN_model(model_name, demo_model_data, num_unique_prints, epochs, verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double check the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#go through all testing images & print results\n",
    "for i in range(num_unique_prints):\n",
    "    test_model_via_index(image_set_name, i, demo_model, sub_index = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Let's try using the same sample set as before\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the multiverse_ids of the cards used in the previous demo\n",
    "prior_multiverse_ids = load_object('prior_multiverse_ids_used.p')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define necessary variables and prepare all images for neural network training\n",
    "\n",
    "image_set_name = 'Prior Card Sample'\n",
    "multiverse_id_list = prior_multiverse_ids\n",
    "num_distortions = 10\n",
    "resize = True\n",
    "verbose = True\n",
    "\n",
    "prior_card_model_data = generate_img_set(image_set_name, multiverse_id_list, num_distortions, resize, verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#provide information about the model and train it!\n",
    "model_name = 'Prior Card Sample Model'\n",
    "epochs = 10\n",
    "verbose = True\n",
    "num_unique_prints = len(multiverse_id_list)\n",
    "\n",
    "prior_card_model = train_CNN_model(model_name, prior_card_model_data, num_unique_prints, epochs, verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#go through all testing images & print results\n",
    "for i in range(num_unique_prints):\n",
    "    test_model_via_index(image_set_name, i, prior_card_model, sub_index = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks for watching, stay tuned for next updates!\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
